{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch.nn.functional as F\n",
    "import torch_scatter as tc\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_params = {\n",
    "    \"seed\": 41,\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 128,\n",
    "    \"init_lr\": 1e-3,\n",
    "    \"lr_reduce_factor\": 0.5,\n",
    "    \"lr_schedule_patience\": 20,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"print_epoch_interval\": 5,\n",
    "    \"max_time\": 12}\n",
    "params_gcn = {\n",
    "    \"L\": 4,\n",
    "    \"hidden_dim\": 145,\n",
    "    \"out_dim\": 145,\n",
    "    \"residual\": True,\n",
    "    \"readout\": \"mean\",\n",
    "    \"in_feat_dropout\": 0.0,\n",
    "    \"dropout\": 0.0,\n",
    "    \"batch_norm\": True,\n",
    "    \"self_loop\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_x(data):\n",
    "    data.x = torch.zeros(data.num_nodes, 1, dtype = torch.int64)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_binary_dataset = pyg.datasets.TUDataset(root='./data', name='REDDIT-BINARY', pre_transform=add_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation1 = torch.randperm(len(reddit_binary_dataset)//2) - 500\n",
    "permutation2 = torch.randperm(len(reddit_binary_dataset)//2) + 500\n",
    "train_fraction = 0.8\n",
    "val_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "train_premutation = torch.cat((permutation1[:int(train_fraction*len(permutation1))], permutation2[:int(train_fraction*len(permutation2))]))\n",
    "val_premutation = torch.cat((permutation1[int(train_fraction*len(permutation1)):int((train_fraction+val_fraction)*len(permutation1))], permutation2[int(train_fraction*len(permutation2)):int((train_fraction+val_fraction)*len(permutation2))]))\n",
    "test_premutation = torch.cat((permutation1[int((train_fraction+val_fraction)*len(permutation1)):], permutation2[int((train_fraction+val_fraction)*len(permutation2)):]))\n",
    "train_dataset = reddit_binary_dataset[train_premutation]\n",
    "val_dataset = reddit_binary_dataset[val_premutation]\n",
    "test_dataset = reddit_binary_dataset[test_premutation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=global_params[\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=global_params[\"batch_size\"], shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=global_params[\"batch_size\"], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GCN, GAT\n",
    "from utils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(params_gcn[\"hidden_dim\"], params_gcn[\"hidden_dim\"], params_gcn[\"out_dim\"], params_gcn[\"L\"]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=global_params[\"init_lr\"], weight_decay=global_params[\"weight_decay\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=global_params[\"lr_reduce_factor\"],\n",
    "                                                       patience=global_params[\"lr_schedule_patience\"], min_lr=global_params[\"min_lr\"], verbose = True)\n",
    "loss = torch.nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tried = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 288:  29%|██▉       | 288/1000 [01:14<03:05,  3.84it/s, time=74.9, lr=1.95e-6, train_loss=0.466, val_loss=0.548, test_loss=0.467, train_metric=0.744, val_metric=0.659, test_metric=0.707] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 308:  31%|███       | 308/1000 [01:28<03:17,  3.50it/s, time=88, lr=1.95e-6, train_loss=0.43, val_loss=0.536, test_loss=0.42, train_metric=0.785, val_metric=0.705, test_metric=0.788]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 420:  42%|████▏     | 420/1000 [02:02<02:48,  3.44it/s, time=122, lr=1.95e-6, train_loss=0.253, val_loss=0.447, test_loss=0.279, train_metric=0.898, val_metric=0.822, test_metric=0.855]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 338:  34%|███▍      | 338/1000 [01:39<03:14,  3.40it/s, time=99.4, lr=1.95e-6, train_loss=0.467, val_loss=0.551, test_loss=0.464, train_metric=0.736, val_metric=0.651, test_metric=0.708] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 505:  50%|█████     | 505/1000 [02:28<02:25,  3.40it/s, time=149, lr=1.95e-6, train_loss=0.274, val_loss=0.426, test_loss=0.292, train_metric=0.891, val_metric=0.836, test_metric=0.854] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gcn_logs = []\n",
    "for _ in range(number_of_tried):\n",
    "    model = GCN(params_gcn[\"hidden_dim\"], params_gcn[\"hidden_dim\"], params_gcn[\"out_dim\"], params_gcn[\"L\"]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=global_params[\"init_lr\"], weight_decay=global_params[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=global_params[\"lr_reduce_factor\"],\n",
    "                                                        patience=global_params[\"lr_schedule_patience\"], min_lr=global_params[\"min_lr\"], verbose = True)\n",
    "    loss = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "    \n",
    "    gcn_logs.append(train(model,loss,  optimizer, scheduler, device, train_dataloader, val_dataloader, test_dataloader, global_params[\"epochs\"], global_params[\"min_lr\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (embedding_layer): Embedding(1, 145)\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x GCNconv(\n",
       "      (lin): Linear(in_features=145, out_features=145, bias=True)\n",
       "      (mp): messagePassing()\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLPReadout(\n",
       "    (FC_layers): ModuleList(\n",
       "      (0): Linear(in_features=145, out_features=72, bias=True)\n",
       "      (1): Linear(in_features=72, out_features=36, bias=True)\n",
       "      (2): Linear(in_features=36, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1907.02204v4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_params =  {\n",
    "        \"L\": 4,\n",
    "        \"hidden_dim\": 144,\n",
    "        \"out_dim\": 144,\n",
    "        \"readout\": \"mean\",\n",
    "        \"n_heads\": 2,\n",
    "        \"in_feat_dropout\": 0.0,\n",
    "        \"dropout\": 0.0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 269:  27%|██▋       | 269/1000 [01:59<05:25,  2.25it/s, time=120, lr=1.56e-6, train_loss=0.73, val_loss=0.745, test_loss=0.836, train_metric=0.74, val_metric=0.696, test_metric=0.727]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 330:  33%|███▎      | 330/1000 [02:26<04:58,  2.25it/s, time=147, lr=1.56e-6, train_loss=0.784, val_loss=0.684, test_loss=0.709, train_metric=0.776, val_metric=0.743, test_metric=0.797] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 265:  26%|██▋       | 265/1000 [01:57<05:26,  2.25it/s, time=118, lr=1.56e-6, train_loss=0.554, val_loss=0.598, test_loss=0.477, train_metric=0.714, val_metric=0.668, test_metric=0.719] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 226:  23%|██▎       | 226/1000 [01:40<05:44,  2.25it/s, time=101, lr=1.56e-6, train_loss=0.579, val_loss=0.633, test_loss=0.69, train_metric=0.749, val_metric=0.71, test_metric=0.727]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 301:  30%|███       | 301/1000 [02:14<05:11,  2.25it/s, time=134, lr=1.56e-6, train_loss=0.685, val_loss=0.634, test_loss=0.642, train_metric=0.712, val_metric=0.694, test_metric=0.714] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gat_logs = []\n",
    "for _ in range(5):\n",
    "    gat_model = GAT(gat_params[\"hidden_dim\"], gat_params[\"hidden_dim\"], gat_params[\"out_dim\"], gat_params[\"L\"], gat_params[\"n_heads\"]).to(device)\n",
    "    gat_optimizer = torch.optim.Adam(gat_model.parameters(), lr=global_params[\"init_lr\"]/10, weight_decay=global_params[\"weight_decay\"])\n",
    "    gat_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(gat_optimizer, mode='min', factor=global_params[\"lr_reduce_factor\"],\n",
    "                                                        patience=global_params[\"lr_schedule_patience\"], min_lr=global_params[\"min_lr\"], verbose = True)\n",
    "    gat_loss = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "    gat_logs.append(train(gat_model, gat_loss, gat_optimizer, gat_scheduler, device, train_dataloader, val_dataloader, test_dataloader, global_params[\"epochs\"], global_params[\"min_lr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_model_with_set2set = GAT(64, 64, 64, gat_params[\"L\"], gat_params[\"n_heads\"], reduce=\"set2set\", n_iter= 10).to(device)\n",
    "gat_optimizer_with_set2set = torch.optim.Adam(gat_model_with_set2set.parameters(), lr=global_params[\"init_lr\"], weight_decay=global_params[\"weight_decay\"])\n",
    "gat_scheduler_with_set2set = torch.optim.lr_scheduler.ReduceLROnPlateau(gat_optimizer_with_set2set, mode='min', factor=global_params[\"lr_reduce_factor\"],\n",
    "                                                         patience=global_params[\"lr_schedule_patience\"], min_lr=global_params[\"min_lr\"], verbose = True)\n",
    "gat_loss_with_set2set = torch.nn.BCEWithLogitsLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2020/omar.ben-said/project/venv/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Epoch 286:  29%|██▊       | 286/1000 [07:35<18:56,  1.59s/it, time=455, lr=1.95e-6, train_loss=0.617, val_loss=0.619, test_loss=0.639, train_metric=0.633, val_metric=0.62, test_metric=0.574]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 285:  28%|██▊       | 285/1000 [07:35<19:02,  1.60s/it, time=455, lr=1.95e-6, train_loss=0.632, val_loss=0.626, test_loss=0.642, train_metric=0.628, val_metric=0.623, test_metric=0.592] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 220:  22%|██▏       | 220/1000 [05:52<20:48,  1.60s/it, time=352, lr=1.95e-6, train_loss=0.651, val_loss=0.641, test_loss=0.646, train_metric=0.63, val_metric=0.619, test_metric=0.582] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 212:  21%|██        | 212/1000 [05:39<21:03,  1.60s/it, time=340, lr=1.95e-6, train_loss=0.79, val_loss=0.708, test_loss=0.735, train_metric=0.508, val_metric=0.481, test_metric=0.464]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 258:  26%|██▌       | 258/1000 [06:51<19:43,  1.59s/it, time=411, lr=1.95e-6, train_loss=0.659, val_loss=0.642, test_loss=0.652, train_metric=0.633, val_metric=0.622, test_metric=0.579] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set2set_logs =[]\n",
    "for _ in range(5):\n",
    "    gat_model_with_set2set = GAT(gat_params[\"hidden_dim\"], gat_params[\"hidden_dim\"]//2, gat_params[\"out_dim\"], gat_params[\"L\"], gat_params[\"n_heads\"], reduce=\"set2set\", n_iter= 30, residual=False).to(device)\n",
    "    gat_optimizer_with_set2set = torch.optim.Adam(gat_model_with_set2set.parameters(), lr=global_params[\"init_lr\"], weight_decay=global_params[\"weight_decay\"])\n",
    "    gat_scheduler_with_set2set = torch.optim.lr_scheduler.ReduceLROnPlateau(gat_optimizer_with_set2set, mode='min', factor=global_params[\"lr_reduce_factor\"],\n",
    "                                                            patience=global_params[\"lr_schedule_patience\"], min_lr=global_params[\"min_lr\"], verbose = True)\n",
    "    gat_loss_with_set2set = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "    set2set_logs.append(train(gat_model_with_set2set, gat_loss_with_set2set, gat_optimizer_with_set2set, gat_scheduler_with_set2set, device, train_dataloader, val_dataloader, test_dataloader, global_params[\"epochs\"], global_params[\"min_lr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "models = [model, gat_model, gat_model_with_set2set]\n",
    "logs = [gcn_logs, gat_logs, set2set_logs]\n",
    "parameter_counts = [count_parameters(model) for model in models]\n",
    "parameter_counts\n",
    "import pickle \n",
    "pickle.dump(logs, open(\"logs_reddit_additive.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98002, 97345, 191665]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
